# 【ToDoリスト】生成AIロールプレイチャットアプリ開発に向けて

## I. 環境準備・調査 (ローカル)

- [ ] **ローカルPCスペック確認:** 特にRAM容量、CPU性能、ストレージ空き容量を確認する。
- [ ] **ローカルLLMツール選定・導入:**
    - [ ] Ollama または LM Studio の情報を確認し、どちらか（または両方）をインストールする。
    * [ ] 簡単なコマンド/操作で動作確認する。
- [ ] **ローカルLLMモデル選定・テスト:**
    - [ ] Ollama/LM Studioで利用可能なモデル（Llama 3 8B Instruct, Mistral 7B Instruct等の量子化版）をいくつか試す。
    - [ ] 応答速度、日本語の自然さ、キャラクター応答のテストなど、簡単な評価を行う。
    - [ ] ローカルAPIサーバー機能を使って、簡単なプログラムからアクセスできるか試す。

## II. 環境準備・調査 (クラウド - Azure)

- [ ] **Azureアカウント作成:** Azure無料アカウントを作成し、利用可能なクレジットや無料枠を確認する。
    - [ ] [Azure 無料アカウント](https://azure.microsoft.com/ja-jp/free/)
- [ ] **Azure OpenAI Service調査:**
    - [ ] 利用可能なモデル（GPT系、DALL-E）とリージョンを確認する。
    * [ ] 料金体系（トークン/画像あたり）を確認する。[公式料金ページ](https://azure.microsoft.com/ja-jp/pricing/details/cognitive-services/openai-service/) (※リンクは変更の可能性あり。Azureポータル内で確認推奨)
    - [ ] 必要であれば利用申請を行う。
    - [ ] 簡単なテスト（ポータル上のプレイグラウンドや簡単なコード）で動作確認する。
- [ ] **Azure Machine Learning (Azure ML)調査 (画像生成向け):**
    - [ ] Azure MLの基本的な概念（ワークスペース、コンピューティング、エンドポイント）を理解する。
    - [ ] モデルカタログで利用可能な画像生成モデル（Stable Diffusion等）があるか確認する。
    - [ ] マネージドエンドポイントへのデプロイ手順と料金体系（主にコンピューティングリソースの稼働時間）を確認する。
    - [ ] Azure OpenAI Service (DALL-E)と比較して、どちらが要件とスキルに合っているか検討する。
- [ ] **コスト試算:**
    - [ ] Azure料金計算ツールを使い、想定される利用量（テキスト生成のトークン数、画像生成枚数）に基づいたコストを見積もる。
    * [ ] [Azure 料金計算ツール](https://azure.microsoft.com/ja-jp/pricing/calculator/)
    - [ ] プロジェクトの予算を設定する。
    - [ ] Azureポータルで予算アラートを設定する方法を確認する。

## III. 技術選定・決定

- [ ] **テキスト生成方法の決定:**
    - [ ] 本番環境: Azure OpenAI Service (GPT) か、Azure ML上のモデルか、(あるいは他のクラウドAPIか) を決定する。
    - [ ] 開発・テスト環境: ローカルLLM (+ Ollama/LM Studio API) を利用するか、クラウドAPIの無料枠を利用するかを決定する。
- [ ] **画像生成方法の決定:**
    - [ ] Azure OpenAI Service (DALL-E) か、Azure ML + マネージドエンドポイントか を決定する。

## IV. 設計・開発

- [x] **タスク①: 外部API(Gemini)疎通確認**
    - [x] APIキー取得
    - [x] `curl`でのAPI呼び出し成功
- [ ] **タスク②: 基本的なWebアプリケーションフロー構築**
    - [x] VSCode環境設定（日本語化、拡張機能インストール）
    - [x] C# Minimal API プロジェクト作成・起動確認
    - [x] 最小限のAPIエンドポイント実装 (例: `/api/chat`)
    - [x] バックエンドAPIの単体テスト成功 (`curl @file`でのテスト)
    - [x] React(TypeScript) プロジェクト作成・起動確認
    - [x] 最小限の画面作成（入力欄、送信ボタン、応答表示エリア）
    - [ ] フロントエンドからバックエンドAPIへのリクエスト送信 ← **Next!**
    - [ ] バックエンドからGemini API呼び出し (ファイル生成不要な方法で)
    - [ ] Gemini APIからの応答をフロントエンドに表示
- [ ] **タスク③: ローカルLLM試用**
    - [ ] (必要なら)メモリ増設
    - [ ] ローカルLLMツール(Ollama等)でモデル実行
    - [ ] ローカルAPIサーバー経由でのアクセス試行
- [ ] **タスク④: API連携先の追加**
    - [ ] バックエンドからローカルLLM APIへのアクセス実装
    - [ ] Azure OpenAI Service (DALL-E 3) 連携実装
- [ ] **タスク⑤: 要件・設計の再整理**
    - [ ] 詳細機能要件の整理
    - [ ] コアロジック（文脈管理、プロンプト生成等）の設計
    - [ ] データ連携フローの設計
- [ ] **タスク⑥: 本格実装**
    - [ ] 要件に基づいた機能実装
- [ ] **タスク⑦: UI改善**
    - [ ] 画面デザイン・使いやすさの向上
